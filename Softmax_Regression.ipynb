{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, parser='auto')\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000,)\n",
      "(70000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 3, 6, 7, 8], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(np.array(y).reshape(-1,1).shape)\n",
    "y.unique()\n",
    "# 아래 구문에서 오류 발생: Y = enc.transform(y[:,np.newaxis]).toarray()\n",
    "# 오류: ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead.\n",
    "# 오류 해결을 위해 np.array로 변환 후  수정 (이후 1곳도 똑같이 수정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.fit(np.array(y).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category count: 1\n",
      "[array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoder 정보\n",
    "print(\"category count:\",enc.n_features_in_)\n",
    "print(enc.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = enc.transform(np.array(y).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], Y[:60000], Y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X, W):\n",
    "    K = np.size(W, 1)\n",
    "    A = np.exp(X @ W)\n",
    "    B = np.diag(1 / (np.reshape(A @ np.ones((K,1)), -1)))\n",
    "    Y = B @ A\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_cross_entropy(X, T, W):\n",
    "    epsilon = 1e-5\n",
    "    N = len(T)\n",
    "    K = np.size(T, 1)\n",
    "    cost = - (1/N) * np.ones((1,N)) @ (np.multiply(np.log(softmax(X, W) + epsilon), T)) @ np.ones((K,1))\n",
    "    return cost\n",
    "\n",
    "def compute_cost_L2(X, T, W, regularization_parameter):\n",
    "    \n",
    "    l2_value = np.sum(np.power(W,2))\n",
    "    N = len(T)\n",
    "    return compute_cost_cross_entropy(X, T, W) + l2_value * regularization_parameter\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W):\n",
    "    return np.argmax((X @ W), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRINT_COST_HISTORY=True\n",
    "\n",
    "def batch_gd(X, T, W, learning_rate, iterations, batch_size, regularization_parameter):\n",
    "    N = len(T)\n",
    "    cost_history = np.zeros((iterations,1))\n",
    "    shuffled_indices = np.random.permutation(N)\n",
    "    X_shuffled = X[shuffled_indices]\n",
    "    T_shuffled = T[shuffled_indices]\n",
    "\n",
    "    for i in range(iterations):\n",
    "        j = i % N\n",
    "        X_batch = X_shuffled[j:j+batch_size]\n",
    "        T_batch = T_shuffled[j:j+batch_size]\n",
    "        # batch가 epoch 경계를 넘어가는 경우, 앞 부분으로 채워줌\n",
    "        if X_batch.shape[0] < batch_size:\n",
    "            X_batch = np.vstack((X_batch, X_shuffled[:(batch_size - X_batch.shape[0])]))\n",
    "            T_batch = np.vstack((T_batch, T_shuffled[:(batch_size - T_batch.shape[0])]))\n",
    "        W = W - (learning_rate/batch_size) * (X_batch.T @ (softmax(X_batch, W) - T_batch))\n",
    "        cost_history[i] = compute_cost_L2(X_batch, T_batch, W, regularization_parameter)\n",
    "        if PRINT_COST_HISTORY & (i % 1000 == 0):\n",
    "            print(cost_history[i][0])\n",
    "            pass\n",
    "\n",
    "    return (cost_history, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization_parameter:0\n",
      "Initial Cost is: 2.3024850979937166 \n",
      "\n",
      "2.2856295547388736\n",
      "0.533706773861257\n",
      "0.42612309186042546\n",
      "0.27603846097365725\n",
      "0.33006763959687463\n",
      "0.34601757232745806\n",
      "0.25667485469011564\n",
      "0.3537483399469502\n",
      "0.2575869655113071\n",
      "0.30443660334905054\n",
      "0.3792868011507706\n",
      "0.41865959757732735\n",
      "0.2890150931062271\n",
      "0.30405594962982024\n",
      "0.16882719256125267\n",
      "0.2172255465070284\n",
      "0.41178749256657043\n",
      "0.41279901147785764\n",
      "0.3939088123527864\n",
      "0.29360361873789936\n",
      "0.28935427898102845\n",
      "0.16374274909996844\n",
      "0.222191771145731\n",
      "0.3852845141285202\n",
      "0.37662850388582303\n",
      "0.30044861495818037\n",
      "0.38435512240742525\n",
      "0.33468956718872134\n",
      "0.30664792151942455\n",
      "0.10237409202305728\n",
      "0.5133677127815894\n",
      "0.30801633811027546\n",
      "0.18680118195842635\n",
      "0.18329545196139843\n",
      "0.34584578453250914\n",
      "0.2501962019146978\n",
      "0.2560984015799574\n",
      "0.30987624028885413\n",
      "0.27591304545895234\n",
      "0.22359983250985405\n",
      "0.2034900462895348\n",
      "0.33435170331719305\n",
      "0.37037946053111\n",
      "0.18114823542827785\n",
      "0.13755521487032782\n",
      "0.11072901526372739\n",
      "0.31530410747555326\n",
      "0.3091590065367027\n",
      "0.40173350604953995\n",
      "0.24606142106044956\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack((np.ones((np.size(X_train, 0),1)),X_train))\n",
    "T = y_train\n",
    "\n",
    "K = np.size(T, 1)\n",
    "M = np.size(X, 1)\n",
    "W = np.zeros((M,K))\n",
    "\n",
    "iterations = 50000\n",
    "learning_rate = 0.01\n",
    "\n",
    "regularization_parameter = 0\n",
    "\n",
    "initial_cost = compute_cost_L2(X, T, W, regularization_parameter)\n",
    "ic_print = initial_cost[0][0]\n",
    "print(f\"regularization_parameter:{regularization_parameter}\")\n",
    "print(\"Initial Cost is: {} \\n\".format(initial_cost[0][0]))\n",
    "\n",
    "(cost_history, W_optimal) = batch_gd(X, T, W, learning_rate, iterations, 64, regularization_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918\n"
     ]
    }
   ],
   "source": [
    "## Accuracy\n",
    "X_ = np.hstack((np.ones((np.size(X_test, 0),1)),X_test))\n",
    "T_ = y_test\n",
    "y_pred = predict(X_, W_optimal)\n",
    "score = float(sum(y_pred == np.argmax(T_, axis=1)))/ float(len(y_test))\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimize regularization_parameter, with multithreading\n",
    "\n",
    "PRINT_COST_HISTORY = False\n",
    "\n",
    "import multiprocessing.dummy as mp\n",
    "from multiprocessing.dummy import Pool\n",
    "import threading\n",
    "\n",
    "\n",
    "\n",
    "def test_work(regularization_parameter, learning_rate):\n",
    "    PRINT_COST_HISTORY = False\n",
    "    X = np.hstack((np.ones((np.size(X_train, 0),1)),X_train))\n",
    "    T = y_train\n",
    "\n",
    "    K = np.size(T, 1)\n",
    "    M = np.size(X, 1)\n",
    "    W = np.zeros((M,K))\n",
    "\n",
    "    iterations = 50000\n",
    "\n",
    "    #initial_cost = compute_cost_L2(X, T, W, regularization_parameter)\n",
    "    #ic_print = initial_cost[0][0]\n",
    "    #print(f\"regularization_parameter:{regularization_parameter}\")\n",
    "    #print(\"Initial Cost is: {} \\n\".format(initial_cost[0][0]))\n",
    "    #print(f\"start {regularization_parameter:.2f}\")\n",
    "    (cost_history, W_optimal) = batch_gd(X, T, W, learning_rate, iterations, 64, regularization_parameter)\n",
    "    ## Accuracy\n",
    "    X_ = np.hstack((np.ones((np.size(X_test, 0),1)),X_test))\n",
    "    T_ = y_test\n",
    "    y_pred = predict(X_, W_optimal)\n",
    "    score = float(sum(y_pred == np.argmax(T_, axis=1)))/ float(len(y_test))\n",
    "    return_str = f\"regularization_parameter:{regularization_parameter:.4f},score:{score}\"\n",
    "    \n",
    "    return (cost_history, W_optimal, score, return_str)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith Pool(2) as p:\\n    regs = [i * 0.2 for i in range(0,100)]\\n    result = p.map(test_work, regs)\\n    p.close()\\n    p.join()\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "hlist=list()\n",
    "for i in range(0,100):\n",
    "    hlist.append(list())\n",
    "    learning_rate = 0.001 + i*i* 0.001\n",
    "    for j in range(0,100): \n",
    "        regs = j * 0.2\n",
    "        result = test_work(regs)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        print(f\"learning_rate:{learning_rate:.4f},{result[3]}\")\n",
    "        result_arg = [learning_rate, regs, result[2],cost_history]\n",
    "        hlist[-1].append(result_arg)\n",
    "'''\n",
    "    \n",
    "\n",
    "\n",
    "              \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
